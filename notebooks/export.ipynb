{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0bfcc28",
   "metadata": {},
   "source": [
    "### Export trained .pth file to other formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "000e720a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of 'models' to sys.path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "# from Models import attention_unet as AttnUNet, vanilla_unet as UNet\n",
    "from networks.attention_unet import AttnUNet\n",
    "from networks.unet import UNet\n",
    "\n",
    "device = torch.device(\"cpu\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 加载模型（假设是UNet）\n",
    "model = AttnUNet(in_channels=3, out_channels=1, channels=[64, 128, 256, 512]).to(device)\n",
    "state_dict = torch.load(\"../runs/attention_unet_0725_2105/attention_unet_best.pth\", map_location=device)\n",
    "# model = UNet(in_channels=3, out_channels=1, channels=[64, 128]).to(device)\n",
    "# state_dict = torch.load(\"../runs/unet_20250725/unet_best.pth\", map_location=device)\n",
    "model.load_state_dict(state_dict=state_dict, strict=False)\n",
    "model.eval()  # 切换到推理模式\n",
    "\n",
    "# 创建示例输入（与模型训练时的输入尺寸一致）\n",
    "dummy_input = torch.randn(1, 3, 256, 256)  # [batch, channels, height, width]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f79c8646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导出ONNX文件\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,\n",
    "    \"model.onnx\",  # 输出文件名\n",
    "    input_names=[\"input\"],  # 输入节点名称\n",
    "    output_names=[\"output\"],  # 输出节点名称\n",
    "    dynamic_axes={\n",
    "        \"input\": {0: \"batch_size\"},  # 动态批次维度\n",
    "        \"output\": {0: \"batch_size\"}\n",
    "    },\n",
    "    opset_version=11  # ONNX算子集版本\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3316ae47",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'onnxruntime'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01monnxruntime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mort\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# 加载ONNX模型\u001b[39;00m\n\u001b[0;32m      4\u001b[0m sess \u001b[38;5;241m=\u001b[39m ort\u001b[38;5;241m.\u001b[39mInferenceSession(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel.onnx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'onnxruntime'"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "\n",
    "# 加载ONNX模型\n",
    "sess = ort.InferenceSession(\"model.onnx\")\n",
    "output = sess.run([\"output\"], {\"input\": dummy_input.numpy()})\n",
    "print(\"ONNX输出形状:\", output[0].shape)  # 应与PyTorch输出一致"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
