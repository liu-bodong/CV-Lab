{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6061642c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler, Subset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Add the parent directory of 'models' to sys.path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "# from Models import attention_unet as AttnUNet, vanilla_unet as UNet\n",
    "from networks.attention_unet import AttnUNet\n",
    "from networks.unet import UNet\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e9a485",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc1c79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrainMRIDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.image_mask_pairs = []\n",
    "        self.transform = transform\n",
    "\n",
    "        # Loop through all patient folders\n",
    "        for patient_folder in os.listdir(root_dir):\n",
    "            patient_path = os.path.join(root_dir, patient_folder)\n",
    "            if not os.path.isdir(patient_path):\n",
    "                continue\n",
    "\n",
    "            # Collect imageâ€“mask pairs\n",
    "            for file in os.listdir(patient_path):\n",
    "                if file.endswith(\".tif\") and \"_mask\" not in file:\n",
    "                    image_path = os.path.join(patient_path, file)\n",
    "                    mask_path = image_path.replace(\".tif\", \"_mask.tif\")\n",
    "                    if os.path.exists(mask_path):\n",
    "                        self.image_mask_pairs.append((image_path, mask_path))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_mask_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, mask_path = self.image_mask_pairs[idx]\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        mask = Image.open(mask_path).convert(\"L\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            mask = self.transform(mask)\n",
    "\n",
    "        mask = (mask > 0).float()  # Binary mask\n",
    "\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620eae94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = AttnUNet(in_channels=3, out_channels=1, channels=[32, 64, 128, 256]).to(device)\n",
    "# model = AttnUNet(in_channels=3, out_channels=1, channels=[64, 128, 256, 512]).to(device)\n",
    "model = UNet(in_channels=3, out_channels=1, channels=[64, 128, 256, 512]).to(device)\n",
    "# model = UNet(in_channels=3, out_channels=1, channels=[64, 128]).to(device)\n",
    "\n",
    "state_dict = torch.load(\"../runs/unet_0727_0437/unet_best.pth\", map_location=device)\n",
    "model.load_state_dict(state_dict=state_dict, strict=False)\n",
    "\n",
    "lr= 3e-4\n",
    "batch_size = 20\n",
    "epochs = 50\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "crterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77335ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.data_utils as data_utils\n",
    "from src.metrics import dice_loss, dice_coefficient\n",
    "\n",
    "train_loader, val_loader = data_utils.create_split_loaders(\n",
    "        dataset='brain_mri',\n",
    "        root_dir='../data/kaggle_3m',\n",
    "        image_size=tuple([256, 256]),\n",
    "        batch_size=12,\n",
    "        val_split=0.2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d10a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform = transforms.Compose([\n",
    "#     transforms.Resize((256, 256)),\n",
    "#     transforms.ToTensor(),\n",
    "# ])\n",
    "\n",
    "# dataset_root = r\"../data/kaggle_3m\"  # Update this path to your dataset location\n",
    "# dataset = BrainMRIDataset(root_dir=dataset_root, transform=transform)\n",
    "# # dataloader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "# val_size=  0.2\n",
    "# num_train = len(dataset)\n",
    "# indices = list(range(num_train))\n",
    "# np.random.shuffle(indices)\n",
    "# split = int(np.floor(val_size * num_train))\n",
    "# train_idx, val_idx = indices[split: ], indices[:split]\n",
    "# train_sampler = SubsetRandomSampler(train_idx)\n",
    "# val_sampler = SubsetRandomSampler(val_idx)\n",
    "# train_loader = DataLoader(dataset, batch_size=batch_size , sampler=train_sampler)\n",
    "# val_loader = DataLoader(dataset,batch_size=batch_size ,sampler=val_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79730b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images, masks = next(iter(train_loader))\n",
    "# print(F\"{images.shape =}\")\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# for i in range(4):\n",
    "#     plt.subplot(2, 4, i+1)\n",
    "#     plt.imshow(images[i].permute(1, 2, 0))\n",
    "#     plt.title(\"MRI Slice\")\n",
    "\n",
    "#     plt.subplot(2, 4, i+5)\n",
    "#     plt.imshow(masks[i][0], cmap='gray')\n",
    "#     plt.title(\"Tumor Mask\")\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5aba32",
   "metadata": {},
   "outputs": [],
   "source": [
    "## try forward pass one input\n",
    "with torch.no_grad():\n",
    "    for images, masks in tqdm(train_loader):\n",
    "        print(f\"Input shape: {images.shape}, Mask shape: {masks.shape}\")\n",
    "        break\n",
    "        \n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = crterion(outputs, masks)\n",
    "\n",
    "        # Get predictions\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        preds = (probs > 0.5).float()\n",
    "\n",
    "        # plt.figure(figsize=(12, 4))\n",
    "\n",
    "        # plt.subplot(1, 3, 1)\n",
    "        # plt.imshow(images[0].cpu().permute(1, 2, 0))\n",
    "        # plt.title(\"Input MRI\")\n",
    "\n",
    "        # plt.subplot(1, 3, 2)\n",
    "        # plt.imshow(masks[0][0].cpu(), cmap='gray')\n",
    "        # plt.title(\"Ground Truth Mask\")\n",
    "\n",
    "        # plt.subplot(1, 3, 3)\n",
    "        # plt.imshow(preds[0][0].cpu(), cmap='gray')\n",
    "        # plt.title(\"Predicted Mask\")\n",
    "\n",
    "        # plt.show()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09df5931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(epochs):\n",
    "#     model.train()\n",
    "#     runing_loss = 0\n",
    "#     train_loader_tqdm = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [Train]\", leave=False)\n",
    "#     for idx, (image, mask) in enumerate(train_loader_tqdm):\n",
    "#         # if idx == 0:\n",
    "#         #     print(f\"Input shape: {image.shape}, Mask shape: {mask.shape}\")\n",
    "#         image = image.float().to(device)\n",
    "#         mask = mask.float().to(device)\n",
    "        \n",
    "#         out = model(image)\n",
    "#         optimizer.zero_grad()\n",
    "#         loss = crterion(out, mask)\n",
    "#         runing_loss += loss.item()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         train_loader_tqdm.set_postfix(loss=loss.item())\n",
    "#     train_loss = runing_loss / (idx + 1)\n",
    "#     model.eval()\n",
    "#     val_loss_runinig = 0\n",
    "#     val_loader_tqdm = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} [Val]\", leave=False)\n",
    "#     with torch.no_grad():\n",
    "#         for idx, (image, mask) in enumerate(val_loader_tqdm):\n",
    "#             image = image.float().to(device)\n",
    "#             mask = mask.float().to(device)\n",
    "#             out = model(image)\n",
    "#             loss = crterion(out, mask)\n",
    "#             val_loss_runinig += loss.item()\n",
    "#             val_loader_tqdm.set_postfix(loss=loss.item())\n",
    "#         val_loss = val_loss_runinig / (idx + 1)\n",
    "#         print(f\"Epoch : {epoch + 1} ... Train Loss:{train_loss : .4f}....Val Loss: {val_loss:.4f}\")\n",
    "# torch.save(model.state_dict(), \"UNet1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a0ff58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create dice coefficient\n",
    "def dice_coef(y_true, y_pred, smooth=100):\n",
    "    y_true_flatten = torch.flatten(y_true)\n",
    "    y_pred_flatten = torch.flatten(y_pred)\n",
    "\n",
    "    intersection = torch.sum(y_true_flatten * y_pred_flatten)\n",
    "    union = torch.sum(y_true_flatten) + torch.sum(y_pred_flatten)\n",
    "    return (2 * intersection + smooth) / (union + smooth)\n",
    "\n",
    "# function to create dice loss\n",
    "def dice_loss(y_true, y_pred, smooth=100):\n",
    "    return -dice_coef(y_true, y_pred, smooth)\n",
    "\n",
    "# function to create iou coefficient\n",
    "def iou_coef(y_true, y_pred, smooth=100):\n",
    "    intersection = torch.sum(y_true * y_pred)\n",
    "    sum = torch.sum(y_true + y_pred)\n",
    "    iou = (intersection + smooth) / (sum - intersection + smooth)\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd0700c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25084631",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.metrics import dice_coefficient, dice_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010c4983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the trained model on the validation dataset\n",
    "model.eval()\n",
    "total_loss = 0.0\n",
    "total_dice = 0.0\n",
    "total_iou = 0.0\n",
    "num_batches = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for image, mask in tqdm(val_loader, desc=\"Validating\"):\n",
    "        image = image.float().to(device)\n",
    "        mask = mask.float().to(device)\n",
    "        output = model(image)\n",
    "        loss = crterion(output, mask)\n",
    "        probs = torch.sigmoid(output)\n",
    "        dice = dice_coef(mask, probs)\n",
    "        iou = iou_coef(mask, probs)\n",
    "        \n",
    "        # dice = dice_coefficient(mask, output)\n",
    "        # iou = dice_coefficient(mask, output)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_dice += dice.item()\n",
    "        total_iou += iou.item()\n",
    "        num_batches += 1\n",
    "\n",
    "mean_loss = total_loss / num_batches\n",
    "mean_dice = total_dice / num_batches\n",
    "mean_iou = total_iou / num_batches\n",
    "\n",
    "print(f\"Validation Loss: {mean_loss:.4f}, Dice Score: {mean_dice:.4f}, IoU Score: {mean_iou:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf151516",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "count = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Collect all batches\n",
    "    val_batches = list(val_loader)\n",
    "    # Shuffle the order\n",
    "    random.shuffle(val_batches)\n",
    "    for i, (image, mask) in enumerate(val_batches):\n",
    "        image = image.to(device)\n",
    "        mask = mask.to(device)\n",
    "\n",
    "        output = model(image)\n",
    "        probs = torch.sigmoid(output)\n",
    "        preds = (probs > 0.5).float()\n",
    "\n",
    "        # Normalize image for visualization\n",
    "        image = (image - image.min()) / (image.max() - image.min()) \n",
    "        \n",
    "        # Process each sample in the batch\n",
    "        for j in range(image.shape[0]):\n",
    "            single_image = image[j]\n",
    "            single_mask = mask[j]\n",
    "            single_pred = preds[j]\n",
    "            \n",
    "            # Check if mask has any positive pixels\n",
    "            mask_sum = single_mask.sum().item()\n",
    "            \n",
    "            if count < 6 and mask_sum > 100:  # Only show masks with substantial tumor area\n",
    "                count += 1\n",
    "                \n",
    "                plt.figure(figsize=(8, 2))\n",
    "                \n",
    "                plt.subplot(1, 3, 1)\n",
    "                plt.imshow(single_image.cpu().permute(1, 2, 0))\n",
    "                plt.title(\"Input MRI\")\n",
    "                plt.axis('off')\n",
    "\n",
    "                plt.subplot(1, 3, 2)\n",
    "                plt.imshow(single_mask[0].cpu(), cmap='gray')\n",
    "                plt.title(f\"Ground Truth Mask\")\n",
    "                plt.axis('off')\n",
    "\n",
    "                plt.subplot(1, 3, 3)\n",
    "                pred_sum = single_pred[0].sum().item()\n",
    "                plt.imshow(single_pred[0].cpu(), cmap='gray')\n",
    "                plt.title(f\"Predicted Mask\")\n",
    "                plt.axis('off')\n",
    "\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "                \n",
    "            if count >= 6:\n",
    "                break\n",
    "        \n",
    "        if count >= 6:\n",
    "            break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
