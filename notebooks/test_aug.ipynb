{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098dd2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler, Subset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddc0b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644eefff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedaaf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = getattr(datasets, \"BrainMRIDataset\")(\n",
    "    root_dir=\"../data/brain_MRI_Buda/kaggle_3m\",\n",
    "    image_size=tuple([256, 256]),\n",
    "    transform=None,\n",
    ")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader, val_loader, _ = datasets.create_split_loaders(\n",
    "    dataset=dataset,\n",
    "    batch_size=4\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096c93af",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, masks = next(iter(train_loader))\n",
    "images.shape, masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f73e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "images[0].shape, masks[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecfa46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "# get one batch\n",
    "images = (images - images.min()) / (images.max() - images.min())\n",
    "masks = masks * 255\n",
    "augs = [\"random_crop\", \"color_jitter\", \"random_rotation\", \"random_crop\"]\n",
    "\n",
    "# plot image and mask\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(4):\n",
    "    img = images[i]\n",
    "    mask = masks[i]\n",
    "    # img, mask = datasets.random_rotation(img, mask)\n",
    "    # img, mask = datasets.random_crop(img, mask)\n",
    "    # img = datasets.color_jitter(img)\n",
    "    # img, mask = datasets.grid_distortion(img, mask)\n",
    "    # img = datasets.gaussian_blur(img, radius_range=(100, 1000.0))\n",
    "    # img = datasets.random_brightness_contrast(img, brightness_limit=0.2, contrast_limit=0.2)\n",
    "    # img, mask = datasets.elastic_transform(img, mask, alpha=30.0, sigma=50, alpha_affine=50)\n",
    "    elasticTransform = transforms.ElasticTransform(alpha=30.0, sigma=50.0)\n",
    "    img = elasticTransform(img)\n",
    "    mask = elasticTransform(mask)\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "                    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(img.permute(1, 2, 0))\n",
    "    plt.title(\"Input MRI\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(mask.squeeze(), cmap='gray')\n",
    "    plt.title(f\"Ground Truth Mask\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
